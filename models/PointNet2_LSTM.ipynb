{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from plyfile import PlyData\n",
    "from tqdm import tqdm\n",
    "from models.pointnet2_utils import PointNetSetAbstraction, PointNetFeaturePropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanPointCloudDataset(Dataset):\n",
    "    def __init__(self, data_dir, num_points=1024):\n",
    "        self.sequences = []\n",
    "        self.num_points = num_points\n",
    "\n",
    "        for folder in sorted(os.listdir(data_dir)):\n",
    "            folder_path = os.path.join(data_dir, folder)\n",
    "            if os.path.isdir(folder_path):\n",
    "                files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.ply')])\n",
    "                if len(files) == 16:  # Ensure each sequence has 16 frames\n",
    "                    self.sequences.append(files)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence_files = self.sequences[idx]\n",
    "        point_clouds = [self.load_ply(file) for file in sequence_files]\n",
    "        return torch.stack(point_clouds, dim=0)  # Shape: [T, N, 3]\n",
    "\n",
    "    def load_ply(self, file_path):\n",
    "        plydata = PlyData.read(file_path)\n",
    "        vertex = plydata['vertex']\n",
    "        points = np.c_[vertex['x'], vertex['y'], vertex['z']].astype(np.float32)\n",
    "        if points.shape[0] < self.num_points:\n",
    "            padding = np.zeros((self.num_points - points.shape[0], 3), dtype=np.float32)\n",
    "            points = np.vstack([points, padding])\n",
    "        elif points.shape[0] > self.num_points:\n",
    "            points = points[:self.num_points, :]\n",
    "        return torch.tensor(points).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNet2FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointNet2FeatureExtractor, self).__init__()\n",
    "        self.sa1 = PointNetSetAbstraction(1024, 0.1, 32, 3, [32, 32, 64], group_all=False)\n",
    "        self.sa2 = PointNetSetAbstraction(256, 0.2, 32, 67, [64, 64, 128], group_all=False)\n",
    "        self.sa3 = PointNetSetAbstraction(64, 0.4, 32, 131, [128, 128, 256], group_all=False)\n",
    "        self.sa4 = PointNetSetAbstraction(16, 0.8, 32, 259, [256, 256, 512], group_all=False)\n",
    "        self.fp1 = PointNetFeaturePropagation(512, [256, 128, 3])  # Example feature propagation for reconstruction\n",
    "\n",
    "    def forward(self, xyz):\n",
    "        l0_xyz = xyz.permute(0, 2, 1)  # [B, 3, N]\n",
    "\n",
    "        l1_xyz, l1_points = self.sa1(l0_xyz, None)\n",
    "\n",
    "        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)\n",
    "\n",
    "        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)\n",
    "\n",
    "        l4_xyz, l4_points = self.sa4(l3_xyz, l3_points)\n",
    "\n",
    "        l4_points = l4_points.mean(dim=2)  # Global average pooling across points dimension to [B, 512]\n",
    "\n",
    "        return l4_points\n",
    "    \n",
    "    def decode(self, features, num_points):\n",
    "        # Create dummy points to satisfy the `points1` and `points2` requirements of the `fp1` method\n",
    "        B = features.size(0)\n",
    "        dummy_points = torch.randn(B, 3, num_points).to(features.device)\n",
    "        x = self.fp1(dummy_points, None, features.unsqueeze(-1).repeat(1, 1, num_points), None)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(SequenceModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = self.lstm(x)  # x: [B, T, input_dim]\n",
    "        return self.fc(output)  # [B, T, input_dim]\n",
    "\n",
    "# Chamfer Distance\n",
    "def chamfer_distance(pc1, pc2):\n",
    "    diff1 = torch.cdist(pc1, pc2, p=2)\n",
    "    diff2 = torch.cdist(pc2, pc1, p=2)\n",
    "    cd = diff1.min(dim=-1)[0].sum(dim=-1) + diff2.min(dim=-1)[0].sum(dim=-1)\n",
    "    return cd.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(pointnet2, seq_model, dataloader, optimizer, epochs, device, save_path):\n",
    "    pointnet2.train()\n",
    "    seq_model.train()\n",
    "    criterion = chamfer_distance\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=len(dataloader), desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\") as pbar:\n",
    "            for batch in dataloader:\n",
    "                batch = batch.to(device)  # [B, T, N, 3]\n",
    "                B, T, N, _ = batch.size()\n",
    "\n",
    "                features_list = []\n",
    "                for t in range(T):\n",
    "                    ft = pointnet2(batch[:, t, :, :])  # [B, 512]\n",
    "                    features_list.append(ft)\n",
    "                features = torch.stack(features_list, dim=1)  # [B, T, 512]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output_features = seq_model(features)  # [B, T, 512]\n",
    "\n",
    "                loss = criterion(output_features.view(B, T, -1), features.view(B, T, -1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "                pbar.update(1)\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1} complete. Average Loss: {avg_loss:.6f}\")\n",
    "\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save({\n",
    "                'pointnet2': pointnet2.state_dict(),\n",
    "                'seq_model': seq_model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'loss': best_loss\n",
    "            }, save_path)\n",
    "            print(f\"Saved best model with loss: {best_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_point_cloud(points, file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(\"ply\\n\")\n",
    "        f.write(\"format ascii 1.0\\n\")\n",
    "        f.write(f\"element vertex {points.shape[0]}\\n\")\n",
    "        f.write(\"property float x\\n\")\n",
    "        f.write(\"property float y\\n\")\n",
    "        f.write(\"property float z\\n\")\n",
    "        f.write(\"end_header\\n\")\n",
    "        for point in points:\n",
    "            f.write(f\"{point[0]} {point[1]} {point[2]}\\n\")\n",
    "\n",
    "# Main execution\n",
    "data_dir = \"your path\"  # Update with your dataset path\n",
    "dataset = HumanPointCloudDataset(data_dir)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pointnet2 = PointNet2FeatureExtractor().to(device)\n",
    "seq_model = SequenceModel(input_dim=512, hidden_dim=256, num_layers=2).to(device)\n",
    "optimizer = torch.optim.Adam(list(pointnet2.parameters()) + list(seq_model.parameters()), lr=1e-3)\n",
    "\n",
    "train_model(pointnet2, seq_model, dataloader, optimizer, epochs=50, device=device, save_path=\"best_model.pth\")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode features to point cloud\n",
    "def decode_features_to_point_cloud(features, pointnet2, num_points=1024):\n",
    "    B, T, feature_dim = features.shape\n",
    "    decoded_points = []\n",
    "    for t in range(T):\n",
    "        x = features[:, t, :]\n",
    "        x = pointnet2.decode(x, num_points)  # Decode using the added decode method\n",
    "        decoded_points.append(x.permute(0, 2, 1))  # [B, N, 3]\n",
    "    return torch.stack(decoded_points, dim=1)  # [B, T, N, 3]\n",
    "\n",
    "# Save decoded point clouds\n",
    "output_dir = \"your path\"\n",
    "pointnet2.eval()\n",
    "seq_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        batch = batch.to(device)  # [B, T, N, 3]\n",
    "        B, T, N, D = batch.size()\n",
    "        features_list = []\n",
    "        for t in range(T):\n",
    "            ft = pointnet2(batch[:, t, :, :])  # [B, 512]\n",
    "            features_list.append(ft)\n",
    "        features = torch.stack(features_list, dim=1)  # [B, T, 512]\n",
    "        \n",
    "        output_features = seq_model(features)  # [B, T, 512]\n",
    "\n",
    "        reconstructed_sequence = decode_features_to_point_cloud(output_features, pointnet2, num_points=N)  # [B, T, N, 3]\n",
    "\n",
    "        for j, sequence in enumerate(reconstructed_sequence):\n",
    "            for timestep, points in enumerate(sequence):\n",
    "                save_point_cloud(points.cpu().numpy(), os.path.join(output_dir, f\"sample_{i * 4 + j}_timestep_{timestep}.ply\"))\n",
    "\n",
    "print(\"Point cloud reconstruction completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
